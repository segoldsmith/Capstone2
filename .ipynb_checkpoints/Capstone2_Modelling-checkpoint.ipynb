{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99ee7d8",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* 1. Import and review data   \n",
    "* 2. K-Nearest Neighbors\n",
    "* 3. Random Forest\n",
    "* 4. LightGBM\n",
    "* 5. XBoost\n",
    "* 6. LightGBM - Categorical Features\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ec1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed122e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Documents\\springboard\\Capstone2\\data\n"
     ]
    }
   ],
   "source": [
    "# Confirm the disk location is correct for importing\n",
    "os.chdir('C:/Users/steve/Documents/springboard/Capstone2/data')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02aee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import Data\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train_df = pd.read_csv('y_train_unscaled.csv')\n",
    "y_test_df = pd.read_csv('y_test_unscaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e04ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace characters that are incompatible with certain models\n",
    "X_train.columns = X_train.columns.str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "X_test.columns = X_test.columns.str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "\n",
    "# Reformat target variable to be readable by machine models\n",
    "y_train = y_train_df.values.ravel()\n",
    "y_test = y_test_df.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719e1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5513783, 166)\n",
      "(5513783,)\n",
      "(1378446, 166)\n",
      "(1378446,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0dcfeab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test data into a smaller sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sample_fraction = 0.2 #.02 for knn and random forest, .2 for lightgbm and xgboost\n",
    "\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=1-sample_fraction, random_state=42)\n",
    "X_test_sample, _, y_test_sample, _ = train_test_split(X_test, y_test, test_size=1-sample_fraction, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20863cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102756, 166)\n",
      "(1102756,)\n",
      "(275689, 166)\n",
      "(275689,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sample.shape)\n",
    "print(y_train_sample.shape)\n",
    "print(X_test_sample.shape)\n",
    "print(y_test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f43a4",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1906075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "# Define function for BayesianOptimization for KNN hyperparapeter search\n",
    "\n",
    "def knn_eval(n_neighbors, leaf_size, p):\n",
    "    \"\"\"\n",
    "    Trains a K-Nearest Neignbors model with given hyperparameters and returns -mse.\n",
    "    \"\"\"    \n",
    "    # Convert parameters to appropriate types\n",
    "    n_neighbors = int(n_neighbors)\n",
    "    leaf_size = int(leaf_size)\n",
    "    p = int(p)\n",
    "    \n",
    "    # Create model\n",
    "    knn = KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        leaf_size=leaf_size,\n",
    "        p=p)\n",
    "    \n",
    "    #train and test model\n",
    "    knn.fit(X_train_sample, y_train_sample)\n",
    "    y_pred_knn = knn.predict(X_test_sample)\n",
    "    mse = mean_squared_error(y_test_sample, y_pred_knn)\n",
    "    return -mse  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e53c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paramater bounds for testing\n",
    "param_bounds_knn = {\n",
    "    'n_neighbors': (1, 30),\n",
    "    'leaf_size': (10, 50),\n",
    "    'p': (1, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd89c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer\n",
    "optimizer_knn = BayesianOptimization(\n",
    "    f=knn_eval,  \n",
    "    pbounds=param_bounds_knn, \n",
    "    random_state=42,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a293d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | leaf_size | n_neig... |     p     |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-505.7   \u001b[39m | \u001b[39m24.98    \u001b[39m | \u001b[39m28.57    \u001b[39m | \u001b[39m1.732    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-582.5   \u001b[39m | \u001b[39m33.95    \u001b[39m | \u001b[39m5.525    \u001b[39m | \u001b[39m1.156    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-506.2   \u001b[39m | \u001b[39m12.32    \u001b[39m | \u001b[39m26.12    \u001b[39m | \u001b[39m1.601    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-991.8   \u001b[39m | \u001b[39m38.32    \u001b[39m | \u001b[39m1.597    \u001b[39m | \u001b[39m1.97     \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-555.5   \u001b[39m | \u001b[39m43.3     \u001b[39m | \u001b[39m7.158    \u001b[39m | \u001b[39m1.182    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-582.5   \u001b[39m | \u001b[39m34.1     \u001b[39m | \u001b[39m5.728    \u001b[39m | \u001b[39m1.234    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-505.9   \u001b[39m | \u001b[39m18.64    \u001b[39m | \u001b[39m27.47    \u001b[39m | \u001b[39m1.447    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-509.0   \u001b[39m | \u001b[39m22.66    \u001b[39m | \u001b[39m22.63    \u001b[39m | \u001b[39m1.947    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-511.1   \u001b[39m | \u001b[39m16.03    \u001b[39m | \u001b[39m20.91    \u001b[39m | \u001b[39m1.637    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-534.4   \u001b[39m | \u001b[39m28.13    \u001b[39m | \u001b[39m10.39    \u001b[39m | \u001b[39m1.292    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-508.0   \u001b[39m | \u001b[39m30.64    \u001b[39m | \u001b[39m23.41    \u001b[39m | \u001b[39m1.253    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-516.4   \u001b[39m | \u001b[39m34.91    \u001b[39m | \u001b[39m16.36    \u001b[39m | \u001b[39m1.017    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-519.8   \u001b[39m | \u001b[39m44.05    \u001b[39m | \u001b[39m14.75    \u001b[39m | \u001b[39m1.073    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-508.0   \u001b[39m | \u001b[39m38.98    \u001b[39m | \u001b[39m23.36    \u001b[39m | \u001b[39m1.796    \u001b[39m |\n",
      "| \u001b[35m15       \u001b[39m | \u001b[35m-505.2   \u001b[39m | \u001b[35m34.01    \u001b[39m | \u001b[35m29.96    \u001b[39m | \u001b[35m1.401    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-505.2   \u001b[39m | \u001b[39m42.89    \u001b[39m | \u001b[39m29.93    \u001b[39m | \u001b[39m1.218    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-508.0   \u001b[39m | \u001b[39m47.78    \u001b[39m | \u001b[39m23.44    \u001b[39m | \u001b[39m1.626    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-534.4   \u001b[39m | \u001b[39m49.91    \u001b[39m | \u001b[39m10.28    \u001b[39m | \u001b[39m1.898    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-505.2   \u001b[39m | \u001b[39m49.98    \u001b[39m | \u001b[39m29.89    \u001b[39m | \u001b[39m1.974    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-517.4   \u001b[39m | \u001b[39m10.12    \u001b[39m | \u001b[39m15.01    \u001b[39m | \u001b[39m1.845    \u001b[39m |\n",
      "=============================================================\n",
      "Best hyperparameters found: {'target': -505.1558146480125, 'params': {'leaf_size': 34.01310455419592, 'n_neighbors': 29.956457584284315, 'p': 1.401197252275951}}\n",
      "CPU times: total: 2h 46min 17s\n",
      "Wall time: 24min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "optimizer_knn.maximize(init_points=5, n_iter=15)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters found:\", optimizer_knn.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b1ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params_knn = optimizer_knn.max['params']\n",
    "best_params_knn['n_neighbors'] = int(best_params_knn['n_neighbors'])\n",
    "best_params_knn['leaf_size'] = int(best_params_knn['leaf_size'])\n",
    "best_params_knn['p'] = int(best_params_knn['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87fe6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 210 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(leaf_size=34, n_neighbors=29, p=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(leaf_size=34, n_neighbors=29, p=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(leaf_size=34, n_neighbors=29, p=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model with the best parameters on the sample data\n",
    "knn_best = KNeighborsRegressor(**best_params_knn)\n",
    "knn_best.fit(X_train_sample, y_train_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3220d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 12s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions\n",
    "y_pred_knn = knn_best.predict(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c14151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 13.934794464346469\n",
      "Mean Squared Error (MSE): 505.1558146480125\n",
      "Root Mean Squared Error (RMSE): 22.4756716172846\n",
      "R-squared (R2): 0.032093685350367385\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae_knn = mean_absolute_error(y_test_sample, y_pred_knn)\n",
    "mse_knn = mean_squared_error(y_test_sample, y_pred_knn)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "r2_knn = r2_score(y_test_sample, y_pred_knn)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae_knn}')\n",
    "print(f'Mean Squared Error (MSE): {mse_knn}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_knn}')\n",
    "print(f'R-squared (R2): {r2_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36c48a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab250d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for BayesianOptimization for random forest hyperparapeter search\n",
    "\n",
    "def rf_eval(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model with given hyperparameters and returns -mse.\n",
    "    \"\"\"\n",
    "    # Convert parameters appripirate types \n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    min_samples_leaf = int(min_samples_leaf)\n",
    "    \n",
    "    \n",
    "    # Create Model\n",
    "    rfbo = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,)\n",
    "    \n",
    "    # Train and test model\n",
    "    rfbo.fit(X_train_sample, y_train_sample)\n",
    "    y_pred_rfbo = rfbo.predict(X_test_sample)\n",
    "    mse = mean_squared_error(y_test_sample, y_pred_rfbo)\n",
    "    return -mse  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79438a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paramater bounds for testing\n",
    "pbounds_rf = {\n",
    "    \"n_estimators\": (50, 200),  \n",
    "    \"max_depth\": (5, 50), \n",
    "    \"min_samples_split\": (2, 10), \n",
    "    \"min_samples_leaf\": (1, 10),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c408c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer\n",
    "optimizer_rf = BayesianOptimization(\n",
    "    f=rf_eval,  \n",
    "    pbounds=pbounds_rf, \n",
    "    random_state=42,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef59bb0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-493.6   \u001b[39m | \u001b[39m21.85    \u001b[39m | \u001b[39m9.556    \u001b[39m | \u001b[39m7.856    \u001b[39m | \u001b[39m139.8    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-498.0   \u001b[39m | \u001b[39m12.02    \u001b[39m | \u001b[39m2.404    \u001b[39m | \u001b[39m2.465    \u001b[39m | \u001b[39m179.9    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-495.3   \u001b[39m | \u001b[39m32.05    \u001b[39m | \u001b[39m7.373    \u001b[39m | \u001b[39m2.165    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-517.9   \u001b[39m | \u001b[39m42.46    \u001b[39m | \u001b[39m2.911    \u001b[39m | \u001b[39m3.455    \u001b[39m | \u001b[39m77.51    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-524.4   \u001b[39m | \u001b[39m49.23    \u001b[39m | \u001b[39m1.063    \u001b[39m | \u001b[39m7.072    \u001b[39m | \u001b[39m160.8    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-494.1   \u001b[39m | \u001b[39m24.78    \u001b[39m | \u001b[39m8.916    \u001b[39m | \u001b[39m4.992    \u001b[39m | \u001b[39m140.1    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-505.5   \u001b[39m | \u001b[39m6.511    \u001b[39m | \u001b[39m7.217    \u001b[39m | \u001b[39m2.358    \u001b[39m | \u001b[39m121.4    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-503.7   \u001b[39m | \u001b[39m7.818    \u001b[39m | \u001b[39m9.627    \u001b[39m | \u001b[39m2.936    \u001b[39m | \u001b[39m153.5    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-500.9   \u001b[39m | \u001b[39m9.873    \u001b[39m | \u001b[39m7.069    \u001b[39m | \u001b[39m9.936    \u001b[39m | \u001b[39m200.0    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-494.6   \u001b[39m | \u001b[39m30.49    \u001b[39m | \u001b[39m8.962    \u001b[39m | \u001b[39m9.303    \u001b[39m | \u001b[39m122.2    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-507.6   \u001b[39m | \u001b[39m5.302    \u001b[39m | \u001b[39m9.015    \u001b[39m | \u001b[39m9.214    \u001b[39m | \u001b[39m50.39    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-495.7   \u001b[39m | \u001b[39m49.19    \u001b[39m | \u001b[39m8.353    \u001b[39m | \u001b[39m2.277    \u001b[39m | \u001b[39m121.6    \u001b[39m |\n",
      "=========================================================================\n",
      "Best hyperparameters found: {'target': -493.563775539169, 'params': {'max_depth': 21.854305348131312, 'min_samples_leaf': 9.556428757689245, 'min_samples_split': 7.855951534491241, 'n_estimators': 139.7987726295555}}\n",
      "CPU times: total: 1h 1min 56s\n",
      "Wall time: 8min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "optimizer_rf.maximize(init_points=4, n_iter=8)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters found:\", optimizer_rf.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c0b7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params_rf = optimizer_rf.max['params']\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['min_samples_split'] = int(best_params_rf['min_samples_split'])\n",
    "best_params_rf['min_samples_leaf'] = int(best_params_rf['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fdfbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 139\n",
      "building tree 2 of 139\n",
      "building tree 3 of 139\n",
      "building tree 4 of 139\n",
      "building tree 5 of 139\n",
      "building tree 6 of 139\n",
      "building tree 7 of 139\n",
      "building tree 8 of 139\n",
      "building tree 9 of 139\n",
      "building tree 10 of 139\n",
      "building tree 11 of 139\n",
      "building tree 12 of 139\n",
      "building tree 13 of 139\n",
      "building tree 14 of 139\n",
      "building tree 15 of 139\n",
      "building tree 16 of 139\n",
      "building tree 17 of 139\n",
      "building tree 18 of 139\n",
      "building tree 19 of 139\n",
      "building tree 20 of 139\n",
      "building tree 21 of 139\n",
      "building tree 22 of 139\n",
      "building tree 23 of 139\n",
      "building tree 24 of 139\n",
      "building tree 25 of 139\n",
      "building tree 26 of 139\n",
      "building tree 27 of 139\n",
      "building tree 28 of 139\n",
      "building tree 29 of 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 15.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 30 of 139\n",
      "building tree 31 of 139\n",
      "building tree 32 of 139\n",
      "building tree 33 of 139\n",
      "building tree 34 of 139\n",
      "building tree 35 of 139\n",
      "building tree 36 of 139\n",
      "building tree 37 of 139\n",
      "building tree 38 of 139\n",
      "building tree 39 of 139\n",
      "building tree 40 of 139\n",
      "building tree 41 of 139\n",
      "building tree 42 of 139\n",
      "building tree 43 of 139\n",
      "building tree 44 of 139\n",
      "building tree 45 of 139\n",
      "building tree 46 of 139\n",
      "building tree 47 of 139\n",
      "building tree 48 of 139\n",
      "building tree 49 of 139\n",
      "building tree 50 of 139\n",
      "building tree 51 of 139\n",
      "building tree 52 of 139\n",
      "building tree 53 of 139\n",
      "building tree 54 of 139\n",
      "building tree 55 of 139\n",
      "building tree 56 of 139\n",
      "building tree 57 of 139\n",
      "building tree 58 of 139\n",
      "building tree 59 of 139\n",
      "building tree 60 of 139\n",
      "building tree 61 of 139\n",
      "building tree 62 of 139\n",
      "building tree 63 of 139\n",
      "building tree 64 of 139\n",
      "building tree 65 of 139\n",
      "building tree 66 of 139\n",
      "building tree 67 of 139\n",
      "building tree 68 of 139\n",
      "building tree 69 of 139\n",
      "building tree 70 of 139\n",
      "building tree 71 of 139\n",
      "building tree 72 of 139\n",
      "building tree 73 of 139\n",
      "building tree 74 of 139\n",
      "building tree 75 of 139\n",
      "building tree 76 of 139\n",
      "building tree 77 of 139\n",
      "building tree 78 of 139\n",
      "building tree 79 of 139\n",
      "building tree 80 of 139\n",
      "building tree 81 of 139\n",
      "building tree 82 of 139\n",
      "building tree 83 of 139\n",
      "building tree 84 of 139\n",
      "building tree 85 of 139\n",
      "building tree 86 of 139\n",
      "building tree 87 of 139\n",
      "building tree 88 of 139\n",
      "building tree 89 of 139\n",
      "building tree 90 of 139\n",
      "building tree 91 of 139\n",
      "building tree 92 of 139\n",
      "building tree 93 of 139\n",
      "building tree 94 of 139\n",
      "building tree 95 of 139\n",
      "building tree 96 of 139\n",
      "building tree 97 of 139\n",
      "building tree 98 of 139\n",
      "building tree 99 of 139\n",
      "building tree 100 of 139\n",
      "building tree 101 of 139\n",
      "building tree 102 of 139\n",
      "building tree 103 of 139\n",
      "building tree 104 of 139\n",
      "building tree 105 of 139\n",
      "building tree 106 of 139\n",
      "building tree 107 of 139\n",
      "building tree 108 of 139\n",
      "building tree 109 of 139\n",
      "building tree 110 of 139\n",
      "building tree 111 of 139\n",
      "building tree 112 of 139\n",
      "building tree 113 of 139\n",
      "building tree 114 of 139\n",
      "building tree 115 of 139\n",
      "building tree 116 of 139\n",
      "building tree 117 of 139\n",
      "building tree 118 of 139\n",
      "building tree 119 of 139\n",
      "building tree 120 of 139\n",
      "building tree 121 of 139\n",
      "building tree 122 of 139\n",
      "building tree 123 of 139\n",
      "building tree 124 of 139\n",
      "building tree 125 of 139\n",
      "building tree 126 of 139\n",
      "building tree 127 of 139\n",
      "building tree 128 of 139\n",
      "building tree 129 of 139\n",
      "building tree 130 of 139\n",
      "building tree 131 of 139\n",
      "building tree 132 of 139\n",
      "building tree 133 of 139\n",
      "building tree 134 of 139\n",
      "building tree 135 of 139\n",
      "building tree 136 of 139\n",
      "building tree 137 of 139\n",
      "building tree 138 of 139\n",
      "building tree 139 of 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 139 out of 139 | elapsed: 94.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12h 7min 12s\n",
      "Wall time: 1h 34min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=21, min_samples_leaf=9, min_samples_split=7,\n",
       "                      n_estimators=139, n_jobs=-1, random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=21, min_samples_leaf=9, min_samples_split=7,\n",
       "                      n_estimators=139, n_jobs=-1, random_state=42, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=21, min_samples_leaf=9, min_samples_split=7,\n",
       "                      n_estimators=139, n_jobs=-1, random_state=42, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the final model with the best parameters\n",
    "rf_best = RandomForestRegressor(**best_params_rf, random_state=42,n_jobs=-1, verbose=2)\n",
    "rf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c495d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.7 s\n",
      "Wall time: 7.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 139 out of 139 | elapsed:    6.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions\n",
    "y_pred_rf_best= rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b070de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 13.674630556613442\n",
      "Mean Squared Error (MSE): 503.62348752929915\n",
      "Root Mean Squared Error (RMSE): 22.44155715473637\n",
      "R-squared (R2): 0.06760678522204433\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf_best)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf_best)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf_best)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae_rf}')\n",
    "print(f'Mean Squared Error (MSE): {mse_rf}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_rf}')\n",
    "print(f'R-squared (R2): {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e04b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc51f93",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a436d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for BayesianOptimization for LightGBM hyperparapeter search\n",
    "\n",
    "def lgb_eval(n_estimators, learning_rate, num_leaves, max_depth, subsample, colsample_bytree ):\n",
    "    \"\"\"\n",
    "    Trains a LightGBM model with given hyperparameters and returns the returns -mse\n",
    "    \"\"\"\n",
    "    # Convert parameters appripirate types\n",
    "    n_estimators =  int(n_estimators)\n",
    "    learning_rate = float(learning_rate)\n",
    "    num_leaves = int(num_leaves)\n",
    "    max_depth = int(max_depth)\n",
    "    subsample = float(subsample)\n",
    "    colsample_bytree = float(colsample_bytree)\n",
    "        \n",
    "    # Create Model\n",
    "    lgbbo = lgb.LGBMRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    num_leaves=num_leaves,\n",
    "    max_depth=max_depth,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    random_state=42)\n",
    "    \n",
    "    # Train and test model\n",
    "    lgbbo.fit(X_train_sample, y_train_sample)\n",
    "    y_pred_lgbbo = lgbbo.predict(X_test_sample)\n",
    "    mse = mean_squared_error(y_test_sample, y_pred_lgbbo)\n",
    "    return -mse  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f958198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paramater bounds for testing\n",
    "param_bounds_lgb = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'learning_rate': (0.01, 0.2),    \n",
    "    'num_leaves': (20, 100),\n",
    "    'max_depth': (5, 50),  \n",
    "    'subsample': (0.6, 1.0),\n",
    "    \"colsample_bytree\": (0.6, 1.0)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af0aead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer\n",
    "optimizer_lgb = BayesianOptimization(\n",
    "    f=lgb_eval,\n",
    "    pbounds=param_bounds_lgb,\n",
    "    random_state=42,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21cdc9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-493.2   \u001b[39m | \u001b[39m0.7498   \u001b[39m | \u001b[39m0.1906   \u001b[39m | \u001b[39m37.94    \u001b[39m | \u001b[39m339.5    \u001b[39m | \u001b[39m32.48    \u001b[39m | \u001b[39m0.6624   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-494.9   \u001b[39m | \u001b[39m0.6232   \u001b[39m | \u001b[39m0.1746   \u001b[39m | \u001b[39m32.05    \u001b[39m | \u001b[39m383.2    \u001b[39m | \u001b[39m21.65    \u001b[39m | \u001b[39m0.988    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-497.0   \u001b[39m | \u001b[39m0.933    \u001b[39m | \u001b[39m0.05034  \u001b[39m | \u001b[39m13.18    \u001b[39m | \u001b[39m173.4    \u001b[39m | \u001b[39m44.34    \u001b[39m | \u001b[39m0.8099   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-497.1   \u001b[39m | \u001b[39m0.7728   \u001b[39m | \u001b[39m0.06533  \u001b[39m | \u001b[39m32.53    \u001b[39m | \u001b[39m155.8    \u001b[39m | \u001b[39m43.37    \u001b[39m | \u001b[39m0.7465   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m-491.9   \u001b[39m | \u001b[35m0.7824   \u001b[39m | \u001b[35m0.1592   \u001b[39m | \u001b[35m13.99    \u001b[39m | \u001b[35m305.7    \u001b[39m | \u001b[35m67.39    \u001b[39m | \u001b[35m0.6186   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-495.3   \u001b[39m | \u001b[39m0.843    \u001b[39m | \u001b[39m0.0424   \u001b[39m | \u001b[39m7.927    \u001b[39m | \u001b[39m479.6    \u001b[39m | \u001b[39m97.25    \u001b[39m | \u001b[39m0.9234   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-499.9   \u001b[39m | \u001b[39m0.7218   \u001b[39m | \u001b[39m0.02856  \u001b[39m | \u001b[39m35.79    \u001b[39m | \u001b[39m276.1    \u001b[39m | \u001b[39m29.76    \u001b[39m | \u001b[39m0.7981   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-492.2   \u001b[39m | \u001b[39m0.6138   \u001b[39m | \u001b[39m0.1828   \u001b[39m | \u001b[39m16.65    \u001b[39m | \u001b[39m365.0    \u001b[39m | \u001b[39m44.94    \u001b[39m | \u001b[39m0.808    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-492.2   \u001b[39m | \u001b[39m0.8187   \u001b[39m | \u001b[39m0.04512  \u001b[39m | \u001b[39m48.63    \u001b[39m | \u001b[39m410.1    \u001b[39m | \u001b[39m95.16    \u001b[39m | \u001b[39m0.9579   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-496.4   \u001b[39m | \u001b[39m0.8392   \u001b[39m | \u001b[39m0.1852   \u001b[39m | \u001b[39m8.982    \u001b[39m | \u001b[39m178.4    \u001b[39m | \u001b[39m23.62    \u001b[39m | \u001b[39m0.7301   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m11       \u001b[39m | \u001b[35m-491.2   \u001b[39m | \u001b[35m0.8924   \u001b[39m | \u001b[35m0.09801  \u001b[39m | \u001b[35m19.58    \u001b[39m | \u001b[35m343.5    \u001b[39m | \u001b[35m90.1     \u001b[39m | \u001b[35m0.9535   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m-490.7   \u001b[39m | \u001b[35m0.8198   \u001b[39m | \u001b[35m0.1072   \u001b[39m | \u001b[35m49.23    \u001b[39m | \u001b[35m409.2    \u001b[39m | \u001b[35m95.07    \u001b[39m | \u001b[35m0.8312   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8587   \u001b[39m | \u001b[39m0.1573   \u001b[39m | \u001b[39m19.04    \u001b[39m | \u001b[39m344.3    \u001b[39m | \u001b[39m87.88    \u001b[39m | \u001b[39m0.8503   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6368   \u001b[39m | \u001b[39m0.08895  \u001b[39m | \u001b[39m48.24    \u001b[39m | \u001b[39m406.0    \u001b[39m | \u001b[39m93.83    \u001b[39m | \u001b[39m0.9499   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-493.8   \u001b[39m | \u001b[39m0.9778   \u001b[39m | \u001b[39m0.03388  \u001b[39m | \u001b[39m14.98    \u001b[39m | \u001b[39m340.5    \u001b[39m | \u001b[39m85.84    \u001b[39m | \u001b[39m0.7371   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m16       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6687   \u001b[39m | \u001b[39m0.1021   \u001b[39m | \u001b[39m20.57    \u001b[39m | \u001b[39m348.7    \u001b[39m | \u001b[39m91.4     \u001b[39m | \u001b[39m0.9575   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-490.9   \u001b[39m | \u001b[39m0.757    \u001b[39m | \u001b[39m0.1777   \u001b[39m | \u001b[39m15.89    \u001b[39m | \u001b[39m347.3    \u001b[39m | \u001b[39m91.9     \u001b[39m | \u001b[39m0.7009   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.6124   \u001b[39m | \u001b[39m0.1321   \u001b[39m | \u001b[39m16.02    \u001b[39m | \u001b[39m343.3    \u001b[39m | \u001b[39m96.6     \u001b[39m | \u001b[39m0.8716   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-495.9   \u001b[39m | \u001b[39m0.6375   \u001b[39m | \u001b[39m0.01938  \u001b[39m | \u001b[39m13.44    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m96.68    \u001b[39m | \u001b[39m0.9308   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.9795   \u001b[39m | \u001b[39m0.106    \u001b[39m | \u001b[39m22.67    \u001b[39m | \u001b[39m342.2    \u001b[39m | \u001b[39m95.82    \u001b[39m | \u001b[39m0.8041   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-490.9   \u001b[39m | \u001b[39m0.9091   \u001b[39m | \u001b[39m0.1259   \u001b[39m | \u001b[39m25.23    \u001b[39m | \u001b[39m347.9    \u001b[39m | \u001b[39m97.74    \u001b[39m | \u001b[39m0.8506   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6756   \u001b[39m | \u001b[39m0.1502   \u001b[39m | \u001b[39m28.41    \u001b[39m | \u001b[39m349.0    \u001b[39m | \u001b[39m91.84    \u001b[39m | \u001b[39m0.9179   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.7267   \u001b[39m | \u001b[39m0.166    \u001b[39m | \u001b[39m27.32    \u001b[39m | \u001b[39m343.0    \u001b[39m | \u001b[39m91.97    \u001b[39m | \u001b[39m0.6264   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.6481   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m34.14    \u001b[39m | \u001b[39m344.2    \u001b[39m | \u001b[39m94.58    \u001b[39m | \u001b[39m0.8021   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.7883   \u001b[39m | \u001b[39m0.1399   \u001b[39m | \u001b[39m36.27    \u001b[39m | \u001b[39m347.6    \u001b[39m | \u001b[39m87.7     \u001b[39m | \u001b[39m0.6491   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-496.9   \u001b[39m | \u001b[39m0.6247   \u001b[39m | \u001b[39m0.01621  \u001b[39m | \u001b[39m34.69    \u001b[39m | \u001b[39m340.1    \u001b[39m | \u001b[39m88.65    \u001b[39m | \u001b[39m0.9066   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-494.8   \u001b[39m | \u001b[39m0.8831   \u001b[39m | \u001b[39m0.0176   \u001b[39m | \u001b[39m32.32    \u001b[39m | \u001b[39m349.0    \u001b[39m | \u001b[39m96.82    \u001b[39m | \u001b[39m0.6284   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-492.1   \u001b[39m | \u001b[39m0.7162   \u001b[39m | \u001b[39m0.04259  \u001b[39m | \u001b[39m49.67    \u001b[39m | \u001b[39m406.1    \u001b[39m | \u001b[39m99.99    \u001b[39m | \u001b[39m0.79     \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.9634   \u001b[39m | \u001b[39m0.1738   \u001b[39m | \u001b[39m20.53    \u001b[39m | \u001b[39m345.9    \u001b[39m | \u001b[39m95.98    \u001b[39m | \u001b[39m0.6947   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m30       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.6855   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m29.77    \u001b[39m | \u001b[39m347.4    \u001b[39m | \u001b[39m87.21    \u001b[39m | \u001b[39m0.6646   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.7006   \u001b[39m | \u001b[39m0.07743  \u001b[39m | \u001b[39m24.29    \u001b[39m | \u001b[39m345.0    \u001b[39m | \u001b[39m88.71    \u001b[39m | \u001b[39m0.916    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.9764   \u001b[39m | \u001b[39m0.162    \u001b[39m | \u001b[39m29.17    \u001b[39m | \u001b[39m341.2    \u001b[39m | \u001b[39m97.52    \u001b[39m | \u001b[39m0.8768   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.8895   \u001b[39m | \u001b[39m0.1034   \u001b[39m | \u001b[39m18.65    \u001b[39m | \u001b[39m350.7    \u001b[39m | \u001b[39m85.85    \u001b[39m | \u001b[39m0.9292   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.8095   \u001b[39m | \u001b[39m0.1033   \u001b[39m | \u001b[39m35.76    \u001b[39m | \u001b[39m353.1    \u001b[39m | \u001b[39m87.13    \u001b[39m | \u001b[39m0.6107   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.7182   \u001b[39m | \u001b[39m0.1435   \u001b[39m | \u001b[39m27.43    \u001b[39m | \u001b[39m353.8    \u001b[39m | \u001b[39m87.22    \u001b[39m | \u001b[39m0.9052   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8761   \u001b[39m | \u001b[39m0.1496   \u001b[39m | \u001b[39m31.52    \u001b[39m | \u001b[39m354.4    \u001b[39m | \u001b[39m79.57    \u001b[39m | \u001b[39m0.8664   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.7861   \u001b[39m | \u001b[39m0.09607  \u001b[39m | \u001b[39m26.63    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m79.63    \u001b[39m | \u001b[39m0.6329   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-493.0   \u001b[39m | \u001b[39m0.9686   \u001b[39m | \u001b[39m0.04646  \u001b[39m | \u001b[39m38.89    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m82.27    \u001b[39m | \u001b[39m0.721    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.7842   \u001b[39m | \u001b[39m0.1406   \u001b[39m | \u001b[39m27.82    \u001b[39m | \u001b[39m358.7    \u001b[39m | \u001b[39m81.57    \u001b[39m | \u001b[39m0.8031   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.8854   \u001b[39m | \u001b[39m0.1557   \u001b[39m | \u001b[39m19.91    \u001b[39m | \u001b[39m357.5    \u001b[39m | \u001b[39m81.27    \u001b[39m | \u001b[39m0.6382   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-491.9   \u001b[39m | \u001b[39m0.6863   \u001b[39m | \u001b[39m0.09805  \u001b[39m | \u001b[39m23.44    \u001b[39m | \u001b[39m358.5    \u001b[39m | \u001b[39m74.34    \u001b[39m | \u001b[39m0.6907   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-492.8   \u001b[39m | \u001b[39m0.8604   \u001b[39m | \u001b[39m0.03836  \u001b[39m | \u001b[39m19.58    \u001b[39m | \u001b[39m337.1    \u001b[39m | \u001b[39m98.03    \u001b[39m | \u001b[39m0.7823   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-494.2   \u001b[39m | \u001b[39m0.602    \u001b[39m | \u001b[39m0.02969  \u001b[39m | \u001b[39m33.7     \u001b[39m | \u001b[39m361.6    \u001b[39m | \u001b[39m85.53    \u001b[39m | \u001b[39m0.6644   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m44       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.9381   \u001b[39m | \u001b[39m0.1094   \u001b[39m | \u001b[39m39.66    \u001b[39m | \u001b[39m350.0    \u001b[39m | \u001b[39m91.72    \u001b[39m | \u001b[39m0.951    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8137   \u001b[39m | \u001b[39m0.1144   \u001b[39m | \u001b[39m22.87    \u001b[39m | \u001b[39m357.6    \u001b[39m | \u001b[39m87.97    \u001b[39m | \u001b[39m0.9414   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-493.4   \u001b[39m | \u001b[39m0.8412   \u001b[39m | \u001b[39m0.03587  \u001b[39m | \u001b[39m20.43    \u001b[39m | \u001b[39m363.6    \u001b[39m | \u001b[39m82.66    \u001b[39m | \u001b[39m0.7976   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.8035   \u001b[39m | \u001b[39m0.1824   \u001b[39m | \u001b[39m23.83    \u001b[39m | \u001b[39m354.0    \u001b[39m | \u001b[39m84.26    \u001b[39m | \u001b[39m0.8697   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.7469   \u001b[39m | \u001b[39m0.1286   \u001b[39m | \u001b[39m14.02    \u001b[39m | \u001b[39m355.6    \u001b[39m | \u001b[39m77.08    \u001b[39m | \u001b[39m0.6802   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-491.9   \u001b[39m | \u001b[39m0.8837   \u001b[39m | \u001b[39m0.08547  \u001b[39m | \u001b[39m17.7     \u001b[39m | \u001b[39m352.9    \u001b[39m | \u001b[39m79.08    \u001b[39m | \u001b[39m0.7729   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-492.3   \u001b[39m | \u001b[39m0.7981   \u001b[39m | \u001b[39m0.08442  \u001b[39m | \u001b[39m11.67    \u001b[39m | \u001b[39m359.0    \u001b[39m | \u001b[39m71.36    \u001b[39m | \u001b[39m0.758    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-493.2   \u001b[39m | \u001b[39m0.9205   \u001b[39m | \u001b[39m0.04095  \u001b[39m | \u001b[39m14.38    \u001b[39m | \u001b[39m355.7    \u001b[39m | \u001b[39m84.88    \u001b[39m | \u001b[39m0.7245   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-491.5   \u001b[39m | \u001b[39m0.8569   \u001b[39m | \u001b[39m0.1308   \u001b[39m | \u001b[39m30.25    \u001b[39m | \u001b[39m356.5    \u001b[39m | \u001b[39m73.2     \u001b[39m | \u001b[39m0.9018   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-493.6   \u001b[39m | \u001b[39m0.7271   \u001b[39m | \u001b[39m0.03064  \u001b[39m | \u001b[39m26.27    \u001b[39m | \u001b[39m357.9    \u001b[39m | \u001b[39m93.55    \u001b[39m | \u001b[39m0.9044   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-495.0   \u001b[39m | \u001b[39m0.9127   \u001b[39m | \u001b[39m0.03807  \u001b[39m | \u001b[39m9.088    \u001b[39m | \u001b[39m349.5    \u001b[39m | \u001b[39m73.58    \u001b[39m | \u001b[39m0.8963   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-494.0   \u001b[39m | \u001b[39m0.7664   \u001b[39m | \u001b[39m0.03668  \u001b[39m | \u001b[39m30.26    \u001b[39m | \u001b[39m349.7    \u001b[39m | \u001b[39m70.25    \u001b[39m | \u001b[39m0.8892   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.9053   \u001b[39m | \u001b[39m0.1724   \u001b[39m | \u001b[39m31.54    \u001b[39m | \u001b[39m361.2    \u001b[39m | \u001b[39m76.53    \u001b[39m | \u001b[39m0.6179   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-494.6   \u001b[39m | \u001b[39m0.826    \u001b[39m | \u001b[39m0.03258  \u001b[39m | \u001b[39m31.84    \u001b[39m | \u001b[39m361.0    \u001b[39m | \u001b[39m68.53    \u001b[39m | \u001b[39m0.9207   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m58       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.7266   \u001b[39m | \u001b[39m0.1852   \u001b[39m | \u001b[39m35.12    \u001b[39m | \u001b[39m340.1    \u001b[39m | \u001b[39m99.89    \u001b[39m | \u001b[39m0.636    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m-492.1   \u001b[39m | \u001b[39m0.9412   \u001b[39m | \u001b[39m0.05933  \u001b[39m | \u001b[39m42.57    \u001b[39m | \u001b[39m342.5    \u001b[39m | \u001b[39m94.67    \u001b[39m | \u001b[39m0.6863   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-492.0   \u001b[39m | \u001b[39m0.7522   \u001b[39m | \u001b[39m0.05823  \u001b[39m | \u001b[39m49.23    \u001b[39m | \u001b[39m408.4    \u001b[39m | \u001b[39m89.1     \u001b[39m | \u001b[39m0.6895   \u001b[39m |\n",
      "=================================================================================================\n",
      "Best hyperparameters found: {'target': -490.6941216113791, 'params': {'colsample_bytree': 0.819758663105755, 'learning_rate': 0.1071949436149192, 'max_depth': 49.23290923768107, 'n_estimators': 409.1520297877578, 'num_leaves': 95.06636520965252, 'subsample': 0.8311833080516193}}\n",
      "CPU times: total: 1h 37s\n",
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "optimizer_lgb.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters found:\", optimizer_lgb.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "052d38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params_lgb = optimizer_lgb.max['params']\n",
    "best_params_lgb['n_estimators'] = int(best_params_lgb['n_estimators'])\n",
    "best_params_lgb['learning_rate'] = float(best_params_lgb['learning_rate'])\n",
    "best_params_lgb['num_leaves'] = int(best_params_lgb['num_leaves'])\n",
    "best_params_lgb['max_depth'] = int(best_params_lgb['max_depth'])\n",
    "best_params_lgb['subsample'] = float(best_params_lgb['subsample'])\n",
    "best_params_lgb['colsample_bytree'] = float(best_params_lgb['colsample_bytree'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "041f9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 585\n",
      "[LightGBM] [Info] Number of data points in the train set: 5513783, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score 5.711103\n",
      "CPU times: total: 4min 45s\n",
      "Wall time: 43.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the final model with the best parameters\n",
    "lgb_best = lgb.LGBMRegressor(**best_params_lgb, random_state=42)\n",
    "lgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4af3fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 38.9 s\n",
      "Wall time: 6.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "446d13bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 13.49468480154234\n",
      "Mean Squared Error (MSE): 493.12285554102556\n",
      "Root Mean Squared Error (RMSE): 22.206369706483443\n",
      "R-squared (R2): 0.08704733606842852\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = np.sqrt(mse_lgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae_lgb}')\n",
    "print(f'Mean Squared Error (MSE): {mse_lgb}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lgb}')\n",
    "print(f'R-squared (R2): {r2_lgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece46ec",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "395edf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for BayesianOptimization for XGBoost hyperparapeter search\n",
    "\n",
    "def xgb_eval(n_estimators, learning_rate, max_depth, subsample, colsample_bytree, gamma, min_child_weight, reg_alpha, reg_lambda):\n",
    "    \"\"\"\n",
    "    Trains XGBoot model with given hyperparameters and returns -mse.\n",
    "    \"\"\"\n",
    "    # Convert parameters appripirate types\n",
    "    n_estimators =  int(n_estimators)\n",
    "    learning_rate = float(learning_rate)\n",
    "    max_depth = int(max_depth)\n",
    "    subsample = float(subsample)\n",
    "    colsample_bytree = float(colsample_bytree)\n",
    "    gamma = int(gamma)\n",
    "    min_child_weight = int(min_child_weight)\n",
    "    reg_alpha = int(reg_alpha)\n",
    "    reg_lambda = int(reg_lambda)\n",
    "    \n",
    "    \n",
    "    # Create Model\n",
    "    xgbbo = xgb.XGBRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    gamma = gamma,\n",
    "    min_child_weight = min_child_weight, \n",
    "    reg_alpha = reg_alpha,\n",
    "    reg_lambda = reg_lambda,    \n",
    "    random_state=42)\n",
    "    \n",
    "    #train and test model\n",
    "    xgbbo.fit(X_train_sample, y_train_sample)\n",
    "    y_pred_xgbbo = xgbbo.predict(X_test_sample)\n",
    "    mse = mean_squared_error(y_test_sample, y_pred_xgbbo)\n",
    "    return -mse  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f540cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paramater bounds for testing\n",
    "param_bounds_xgb = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'learning_rate': (0.01, 0.3),    \n",
    "    'max_depth': (3, 10),  \n",
    "    'subsample': (0.5, 1.0),\n",
    "    \"colsample_bytree\": (0.5, 1.0),\n",
    "    \"gamma\": (0, 10),\n",
    "    \"min_child_weight\": (0, 10),\n",
    "    \"reg_alpha\":(0, 10),\n",
    "    \"reg_lambda\":(0, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2091d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer\n",
    "optimizer_xgb = BayesianOptimization(\n",
    "    f=xgb_eval,\n",
    "    pbounds=param_bounds_xgb,\n",
    "    random_state=42,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1cad809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-493.3   \u001b[39m | \u001b[39m0.6873   \u001b[39m | \u001b[39m9.507    \u001b[39m | \u001b[39m0.2223   \u001b[39m | \u001b[39m7.191    \u001b[39m | \u001b[39m1.56     \u001b[39m | \u001b[39m162.4    \u001b[39m | \u001b[39m0.5808   \u001b[39m | \u001b[39m8.662    \u001b[39m | \u001b[39m0.8006   \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-493.9   \u001b[39m | \u001b[39m0.854    \u001b[39m | \u001b[39m0.2058   \u001b[39m | \u001b[39m0.2913   \u001b[39m | \u001b[39m8.827    \u001b[39m | \u001b[39m2.123    \u001b[39m | \u001b[39m172.7    \u001b[39m | \u001b[39m1.834    \u001b[39m | \u001b[39m3.042    \u001b[39m | \u001b[39m0.7624   \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-501.0   \u001b[39m | \u001b[39m0.716    \u001b[39m | \u001b[39m2.912    \u001b[39m | \u001b[39m0.1874   \u001b[39m | \u001b[39m3.976    \u001b[39m | \u001b[39m2.921    \u001b[39m | \u001b[39m246.5    \u001b[39m | \u001b[39m4.561    \u001b[39m | \u001b[39m7.852    \u001b[39m | \u001b[39m0.5998   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-507.4   \u001b[39m | \u001b[39m0.7571   \u001b[39m | \u001b[39m5.924    \u001b[39m | \u001b[39m0.02347  \u001b[39m | \u001b[39m7.253    \u001b[39m | \u001b[39m1.705    \u001b[39m | \u001b[39m126.0    \u001b[39m | \u001b[39m9.489    \u001b[39m | \u001b[39m9.656    \u001b[39m | \u001b[39m0.9042   \u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m-493.3   \u001b[39m | \u001b[35m0.6523   \u001b[39m | \u001b[35m0.9767   \u001b[39m | \u001b[35m0.2084   \u001b[39m | \u001b[35m6.081    \u001b[39m | \u001b[35m1.22     \u001b[39m | \u001b[35m298.1    \u001b[39m | \u001b[35m0.3439   \u001b[39m | \u001b[35m9.093    \u001b[39m | \u001b[35m0.6294   \u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-491.6   \u001b[39m | \u001b[35m0.8313   \u001b[39m | \u001b[35m3.117    \u001b[39m | \u001b[35m0.1608   \u001b[39m | \u001b[35m6.827    \u001b[39m | \u001b[35m1.849    \u001b[39m | \u001b[35m487.8    \u001b[39m | \u001b[35m7.751    \u001b[39m | \u001b[35m9.395    \u001b[39m | \u001b[35m0.9474   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-506.6   \u001b[39m | \u001b[39m0.7989   \u001b[39m | \u001b[39m9.219    \u001b[39m | \u001b[39m0.03566  \u001b[39m | \u001b[39m4.372    \u001b[39m | \u001b[39m0.4523   \u001b[39m | \u001b[39m230.1    \u001b[39m | \u001b[39m3.887    \u001b[39m | \u001b[39m2.713    \u001b[39m | \u001b[39m0.9144   \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-504.1   \u001b[39m | \u001b[39m0.6784   \u001b[39m | \u001b[39m2.809    \u001b[39m | \u001b[39m0.1674   \u001b[39m | \u001b[39m3.986    \u001b[39m | \u001b[39m8.022    \u001b[39m | \u001b[39m129.8    \u001b[39m | \u001b[39m9.869    \u001b[39m | \u001b[39m7.722    \u001b[39m | \u001b[39m0.5994   \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-493.4   \u001b[39m | \u001b[39m0.5028   \u001b[39m | \u001b[39m8.155    \u001b[39m | \u001b[39m0.215    \u001b[39m | \u001b[39m8.103    \u001b[39m | \u001b[39m7.713    \u001b[39m | \u001b[39m129.6    \u001b[39m | \u001b[39m3.585    \u001b[39m | \u001b[39m1.159    \u001b[39m | \u001b[39m0.9316   \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-501.9   \u001b[39m | \u001b[39m0.8116   \u001b[39m | \u001b[39m3.309    \u001b[39m | \u001b[39m0.02843  \u001b[39m | \u001b[39m5.177    \u001b[39m | \u001b[39m3.252    \u001b[39m | \u001b[39m391.8    \u001b[39m | \u001b[39m6.376    \u001b[39m | \u001b[39m8.872    \u001b[39m | \u001b[39m0.7361   \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-496.9   \u001b[39m | \u001b[39m0.7568   \u001b[39m | \u001b[39m4.564    \u001b[39m | \u001b[39m0.2964   \u001b[39m | \u001b[39m3.244    \u001b[39m | \u001b[39m3.817    \u001b[39m | \u001b[39m487.4    \u001b[39m | \u001b[39m3.694    \u001b[39m | \u001b[39m3.984    \u001b[39m | \u001b[39m0.8157   \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-494.0   \u001b[39m | \u001b[39m0.6161   \u001b[39m | \u001b[39m8.732    \u001b[39m | \u001b[39m0.2497   \u001b[39m | \u001b[39m7.581    \u001b[39m | \u001b[39m8.313    \u001b[39m | \u001b[39m129.5    \u001b[39m | \u001b[39m3.191    \u001b[39m | \u001b[39m2.886    \u001b[39m | \u001b[39m0.8908   \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-495.3   \u001b[39m | \u001b[39m0.7699   \u001b[39m | \u001b[39m9.754    \u001b[39m | \u001b[39m0.2995   \u001b[39m | \u001b[39m8.948    \u001b[39m | \u001b[39m3.161    \u001b[39m | \u001b[39m497.2    \u001b[39m | \u001b[39m8.94     \u001b[39m | \u001b[39m9.624    \u001b[39m | \u001b[39m0.8301   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-510.8   \u001b[39m | \u001b[39m0.5215   \u001b[39m | \u001b[39m9.48     \u001b[39m | \u001b[39m0.01325  \u001b[39m | \u001b[39m8.856    \u001b[39m | \u001b[39m9.816    \u001b[39m | \u001b[39m147.9    \u001b[39m | \u001b[39m2.509    \u001b[39m | \u001b[39m0.2821   \u001b[39m | \u001b[39m0.9441   \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-505.3   \u001b[39m | \u001b[39m0.848    \u001b[39m | \u001b[39m9.342    \u001b[39m | \u001b[39m0.05587  \u001b[39m | \u001b[39m4.791    \u001b[39m | \u001b[39m3.599    \u001b[39m | \u001b[39m172.3    \u001b[39m | \u001b[39m0.5186   \u001b[39m | \u001b[39m7.575    \u001b[39m | \u001b[39m0.5727   \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-494.6   \u001b[39m | \u001b[39m0.9263   \u001b[39m | \u001b[39m4.112    \u001b[39m | \u001b[39m0.2136   \u001b[39m | \u001b[39m4.518    \u001b[39m | \u001b[39m5.015    \u001b[39m | \u001b[39m493.4    \u001b[39m | \u001b[39m8.776    \u001b[39m | \u001b[39m8.96     \u001b[39m | \u001b[39m0.8157   \u001b[39m |\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m-491.2   \u001b[39m | \u001b[35m0.9207   \u001b[39m | \u001b[35m1.041    \u001b[39m | \u001b[35m0.06535  \u001b[39m | \u001b[35m9.988    \u001b[39m | \u001b[35m0.07574  \u001b[39m | \u001b[35m489.6    \u001b[39m | \u001b[35m9.436    \u001b[39m | \u001b[35m2.741    \u001b[39m | \u001b[35m0.6559   \u001b[39m |\n",
      "| \u001b[35m18       \u001b[39m | \u001b[35m-490.4   \u001b[39m | \u001b[35m0.6954   \u001b[39m | \u001b[35m0.9885   \u001b[39m | \u001b[35m0.1525   \u001b[39m | \u001b[35m8.948    \u001b[39m | \u001b[35m6.929    \u001b[39m | \u001b[35m482.5    \u001b[39m | \u001b[35m9.676    \u001b[39m | \u001b[35m5.43     \u001b[39m | \u001b[35m0.9119   \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-492.9   \u001b[39m | \u001b[39m0.6948   \u001b[39m | \u001b[39m0.02938  \u001b[39m | \u001b[39m0.1447   \u001b[39m | \u001b[39m6.507    \u001b[39m | \u001b[39m0.4729   \u001b[39m | \u001b[39m476.9    \u001b[39m | \u001b[39m7.768    \u001b[39m | \u001b[39m8.424    \u001b[39m | \u001b[39m0.5175   \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-499.3   \u001b[39m | \u001b[39m0.926    \u001b[39m | \u001b[39m7.503    \u001b[39m | \u001b[39m0.2343   \u001b[39m | \u001b[39m7.55     \u001b[39m | \u001b[39m0.2841   \u001b[39m | \u001b[39m477.5    \u001b[39m | \u001b[39m9.822    \u001b[39m | \u001b[39m0.7125   \u001b[39m | \u001b[39m0.6513   \u001b[39m |\n",
      "| \u001b[35m21       \u001b[39m | \u001b[35m-490.1   \u001b[39m | \u001b[35m0.6022   \u001b[39m | \u001b[35m0.7576   \u001b[39m | \u001b[35m0.09173  \u001b[39m | \u001b[35m9.779    \u001b[39m | \u001b[35m8.733    \u001b[39m | \u001b[35m485.0    \u001b[39m | \u001b[35m1.206    \u001b[39m | \u001b[35m9.937    \u001b[39m | \u001b[35m0.7743   \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-490.6   \u001b[39m | \u001b[39m0.9257   \u001b[39m | \u001b[39m0.4652   \u001b[39m | \u001b[39m0.1045   \u001b[39m | \u001b[39m9.17     \u001b[39m | \u001b[39m7.355    \u001b[39m | \u001b[39m474.8    \u001b[39m | \u001b[39m1.404    \u001b[39m | \u001b[39m6.387    \u001b[39m | \u001b[39m0.7514   \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-493.5   \u001b[39m | \u001b[39m0.9971   \u001b[39m | \u001b[39m1.225    \u001b[39m | \u001b[39m0.1528   \u001b[39m | \u001b[39m5.282    \u001b[39m | \u001b[39m9.716    \u001b[39m | \u001b[39m471.1    \u001b[39m | \u001b[39m8.139    \u001b[39m | \u001b[39m8.417    \u001b[39m | \u001b[39m0.7662   \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-497.7   \u001b[39m | \u001b[39m0.5152   \u001b[39m | \u001b[39m6.467    \u001b[39m | \u001b[39m0.1876   \u001b[39m | \u001b[39m4.822    \u001b[39m | \u001b[39m1.453    \u001b[39m | \u001b[39m309.6    \u001b[39m | \u001b[39m2.152    \u001b[39m | \u001b[39m2.174    \u001b[39m | \u001b[39m0.6034   \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.8569   \u001b[39m | \u001b[39m2.496    \u001b[39m | \u001b[39m0.04593  \u001b[39m | \u001b[39m9.59     \u001b[39m | \u001b[39m5.862    \u001b[39m | \u001b[39m463.6    \u001b[39m | \u001b[39m0.02818  \u001b[39m | \u001b[39m8.523    \u001b[39m | \u001b[39m0.7428   \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.8973   \u001b[39m | \u001b[39m0.3979   \u001b[39m | \u001b[39m0.0482   \u001b[39m | \u001b[39m9.536    \u001b[39m | \u001b[39m9.367    \u001b[39m | \u001b[39m453.0    \u001b[39m | \u001b[39m1.897    \u001b[39m | \u001b[39m3.887    \u001b[39m | \u001b[39m0.7675   \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-492.6   \u001b[39m | \u001b[39m0.5074   \u001b[39m | \u001b[39m9.922    \u001b[39m | \u001b[39m0.05716  \u001b[39m | \u001b[39m8.777    \u001b[39m | \u001b[39m2.259    \u001b[39m | \u001b[39m452.0    \u001b[39m | \u001b[39m1.476    \u001b[39m | \u001b[39m7.009    \u001b[39m | \u001b[39m0.8526   \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-498.5   \u001b[39m | \u001b[39m0.7053   \u001b[39m | \u001b[39m1.019    \u001b[39m | \u001b[39m0.206    \u001b[39m | \u001b[39m3.943    \u001b[39m | \u001b[39m0.5591   \u001b[39m | \u001b[39m453.5    \u001b[39m | \u001b[39m8.358    \u001b[39m | \u001b[39m3.312    \u001b[39m | \u001b[39m0.711    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-490.4   \u001b[39m | \u001b[39m0.7329   \u001b[39m | \u001b[39m3.544    \u001b[39m | \u001b[39m0.149    \u001b[39m | \u001b[39m8.053    \u001b[39m | \u001b[39m8.957    \u001b[39m | \u001b[39m438.2    \u001b[39m | \u001b[39m0.6081   \u001b[39m | \u001b[39m6.064    \u001b[39m | \u001b[39m0.9354   \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.984    \u001b[39m | \u001b[39m8.061    \u001b[39m | \u001b[39m0.1724   \u001b[39m | \u001b[39m8.877    \u001b[39m | \u001b[39m9.638    \u001b[39m | \u001b[39m441.9    \u001b[39m | \u001b[39m9.686    \u001b[39m | \u001b[39m5.175    \u001b[39m | \u001b[39m0.7234   \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m-492.7   \u001b[39m | \u001b[39m0.9096   \u001b[39m | \u001b[39m8.66     \u001b[39m | \u001b[39m0.05443  \u001b[39m | \u001b[39m8.918    \u001b[39m | \u001b[39m2.117    \u001b[39m | \u001b[39m432.3    \u001b[39m | \u001b[39m0.757    \u001b[39m | \u001b[39m1.328    \u001b[39m | \u001b[39m0.8274   \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-490.8   \u001b[39m | \u001b[39m0.7336   \u001b[39m | \u001b[39m2.625    \u001b[39m | \u001b[39m0.07346  \u001b[39m | \u001b[39m9.364    \u001b[39m | \u001b[39m9.365    \u001b[39m | \u001b[39m429.2    \u001b[39m | \u001b[39m8.059    \u001b[39m | \u001b[39m8.872    \u001b[39m | \u001b[39m0.5596   \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-500.2   \u001b[39m | \u001b[39m0.9383   \u001b[39m | \u001b[39m1.224    \u001b[39m | \u001b[39m0.143    \u001b[39m | \u001b[39m3.804    \u001b[39m | \u001b[39m9.291    \u001b[39m | \u001b[39m431.4    \u001b[39m | \u001b[39m8.335    \u001b[39m | \u001b[39m0.1275   \u001b[39m | \u001b[39m0.97     \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m34       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.9387   \u001b[39m | \u001b[39m8.017    \u001b[39m | \u001b[39m0.1309   \u001b[39m | \u001b[39m7.716    \u001b[39m | \u001b[39m9.868    \u001b[39m | \u001b[39m428.3    \u001b[39m | \u001b[39m0.605    \u001b[39m | \u001b[39m9.264    \u001b[39m | \u001b[39m0.6207   \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.5287   \u001b[39m | \u001b[39m6.16     \u001b[39m | \u001b[39m0.08328  \u001b[39m | \u001b[39m9.963    \u001b[39m | \u001b[39m0.2544   \u001b[39m | \u001b[39m440.9    \u001b[39m | \u001b[39m4.172    \u001b[39m | \u001b[39m9.201    \u001b[39m | \u001b[39m0.5569   \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-496.3   \u001b[39m | \u001b[39m0.8291   \u001b[39m | \u001b[39m0.4853   \u001b[39m | \u001b[39m0.2803   \u001b[39m | \u001b[39m8.145    \u001b[39m | \u001b[39m2.169    \u001b[39m | \u001b[39m431.5    \u001b[39m | \u001b[39m0.02574  \u001b[39m | \u001b[39m9.371    \u001b[39m | \u001b[39m0.5917   \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-491.5   \u001b[39m | \u001b[39m0.6837   \u001b[39m | \u001b[39m8.581    \u001b[39m | \u001b[39m0.1157   \u001b[39m | \u001b[39m7.96     \u001b[39m | \u001b[39m8.687    \u001b[39m | \u001b[39m442.5    \u001b[39m | \u001b[39m1.103    \u001b[39m | \u001b[39m9.423    \u001b[39m | \u001b[39m0.8155   \u001b[39m |\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-499.2   \u001b[39m | \u001b[39m0.9763   \u001b[39m | \u001b[39m9.442    \u001b[39m | \u001b[39m0.01108  \u001b[39m | \u001b[39m9.178    \u001b[39m | \u001b[39m0.9835   \u001b[39m | \u001b[39m423.8    \u001b[39m | \u001b[39m9.801    \u001b[39m | \u001b[39m9.707    \u001b[39m | \u001b[39m0.961    \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.704    \u001b[39m | \u001b[39m3.515    \u001b[39m | \u001b[39m0.1808   \u001b[39m | \u001b[39m9.787    \u001b[39m | \u001b[39m6.287    \u001b[39m | \u001b[39m283.3    \u001b[39m | \u001b[39m0.04347  \u001b[39m | \u001b[39m7.725    \u001b[39m | \u001b[39m0.8195   \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-499.2   \u001b[39m | \u001b[39m0.6618   \u001b[39m | \u001b[39m5.428    \u001b[39m | \u001b[39m0.1279   \u001b[39m | \u001b[39m4.102    \u001b[39m | \u001b[39m0.8747   \u001b[39m | \u001b[39m281.7    \u001b[39m | \u001b[39m8.58     \u001b[39m | \u001b[39m9.837    \u001b[39m | \u001b[39m0.8697   \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-492.9   \u001b[39m | \u001b[39m0.7557   \u001b[39m | \u001b[39m1.268    \u001b[39m | \u001b[39m0.156    \u001b[39m | \u001b[39m9.933    \u001b[39m | \u001b[39m8.926    \u001b[39m | \u001b[39m295.0    \u001b[39m | \u001b[39m0.6177   \u001b[39m | \u001b[39m0.8579   \u001b[39m | \u001b[39m0.5762   \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-492.1   \u001b[39m | \u001b[39m0.7627   \u001b[39m | \u001b[39m9.624    \u001b[39m | \u001b[39m0.1864   \u001b[39m | \u001b[39m7.394    \u001b[39m | \u001b[39m9.094    \u001b[39m | \u001b[39m273.7    \u001b[39m | \u001b[39m0.2756   \u001b[39m | \u001b[39m0.5485   \u001b[39m | \u001b[39m0.9698   \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.9459   \u001b[39m | \u001b[39m9.287    \u001b[39m | \u001b[39m0.1543   \u001b[39m | \u001b[39m8.383    \u001b[39m | \u001b[39m8.946    \u001b[39m | \u001b[39m285.7    \u001b[39m | \u001b[39m0.1283   \u001b[39m | \u001b[39m0.8138   \u001b[39m | \u001b[39m0.7941   \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-491.6   \u001b[39m | \u001b[39m0.7913   \u001b[39m | \u001b[39m0.1388   \u001b[39m | \u001b[39m0.1107   \u001b[39m | \u001b[39m9.497    \u001b[39m | \u001b[39m4.498    \u001b[39m | \u001b[39m273.5    \u001b[39m | \u001b[39m0.6876   \u001b[39m | \u001b[39m0.5063   \u001b[39m | \u001b[39m0.7886   \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m-494.4   \u001b[39m | \u001b[39m0.7745   \u001b[39m | \u001b[39m0.04746  \u001b[39m | \u001b[39m0.1898   \u001b[39m | \u001b[39m5.269    \u001b[39m | \u001b[39m8.505    \u001b[39m | \u001b[39m348.2    \u001b[39m | \u001b[39m0.1678   \u001b[39m | \u001b[39m7.197    \u001b[39m | \u001b[39m0.6677   \u001b[39m |\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-490.6   \u001b[39m | \u001b[39m0.7208   \u001b[39m | \u001b[39m0.2181   \u001b[39m | \u001b[39m0.06865  \u001b[39m | \u001b[39m9.804    \u001b[39m | \u001b[39m8.82     \u001b[39m | \u001b[39m445.0    \u001b[39m | \u001b[39m7.3      \u001b[39m | \u001b[39m9.285    \u001b[39m | \u001b[39m0.9327   \u001b[39m |\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-493.7   \u001b[39m | \u001b[39m0.6674   \u001b[39m | \u001b[39m9.186    \u001b[39m | \u001b[39m0.02818  \u001b[39m | \u001b[39m9.954    \u001b[39m | \u001b[39m8.992    \u001b[39m | \u001b[39m461.3    \u001b[39m | \u001b[39m0.243    \u001b[39m | \u001b[39m0.02072  \u001b[39m | \u001b[39m0.8548   \u001b[39m |\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.6668   \u001b[39m | \u001b[39m8.653    \u001b[39m | \u001b[39m0.0742   \u001b[39m | \u001b[39m9.59     \u001b[39m | \u001b[39m8.066    \u001b[39m | \u001b[39m336.0    \u001b[39m | \u001b[39m9.764    \u001b[39m | \u001b[39m1.2      \u001b[39m | \u001b[39m0.6375   \u001b[39m |\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-499.1   \u001b[39m | \u001b[39m0.8457   \u001b[39m | \u001b[39m0.4857   \u001b[39m | \u001b[39m0.2454   \u001b[39m | \u001b[39m3.084    \u001b[39m | \u001b[39m0.4254   \u001b[39m | \u001b[39m337.8    \u001b[39m | \u001b[39m8.78     \u001b[39m | \u001b[39m0.8147   \u001b[39m | \u001b[39m0.5493   \u001b[39m |\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-491.6   \u001b[39m | \u001b[39m0.9566   \u001b[39m | \u001b[39m8.389    \u001b[39m | \u001b[39m0.09268  \u001b[39m | \u001b[39m8.873    \u001b[39m | \u001b[39m8.913    \u001b[39m | \u001b[39m331.5    \u001b[39m | \u001b[39m3.088    \u001b[39m | \u001b[39m9.269    \u001b[39m | \u001b[39m0.7906   \u001b[39m |\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-500.0   \u001b[39m | \u001b[39m0.961    \u001b[39m | \u001b[39m9.933    \u001b[39m | \u001b[39m0.2552   \u001b[39m | \u001b[39m9.315    \u001b[39m | \u001b[39m7.017    \u001b[39m | \u001b[39m358.8    \u001b[39m | \u001b[39m3.014    \u001b[39m | \u001b[39m0.4913   \u001b[39m | \u001b[39m0.6089   \u001b[39m |\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-492.6   \u001b[39m | \u001b[39m0.6867   \u001b[39m | \u001b[39m5.561    \u001b[39m | \u001b[39m0.0495   \u001b[39m | \u001b[39m9.571    \u001b[39m | \u001b[39m9.849    \u001b[39m | \u001b[39m324.9    \u001b[39m | \u001b[39m8.155    \u001b[39m | \u001b[39m3.616    \u001b[39m | \u001b[39m0.8153   \u001b[39m |\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-502.9   \u001b[39m | \u001b[39m0.8891   \u001b[39m | \u001b[39m0.4153   \u001b[39m | \u001b[39m0.09475  \u001b[39m | \u001b[39m3.142    \u001b[39m | \u001b[39m9.312    \u001b[39m | \u001b[39m285.2    \u001b[39m | \u001b[39m0.3733   \u001b[39m | \u001b[39m0.3425   \u001b[39m | \u001b[39m0.5989   \u001b[39m |\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-491.9   \u001b[39m | \u001b[39m0.9897   \u001b[39m | \u001b[39m0.3017   \u001b[39m | \u001b[39m0.1553   \u001b[39m | \u001b[39m9.489    \u001b[39m | \u001b[39m9.169    \u001b[39m | \u001b[39m267.6    \u001b[39m | \u001b[39m2.101    \u001b[39m | \u001b[39m9.511    \u001b[39m | \u001b[39m0.5057   \u001b[39m |\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-492.2   \u001b[39m | \u001b[39m0.5974   \u001b[39m | \u001b[39m9.971    \u001b[39m | \u001b[39m0.08346  \u001b[39m | \u001b[39m9.911    \u001b[39m | \u001b[39m0.9466   \u001b[39m | \u001b[39m267.7    \u001b[39m | \u001b[39m0.06896  \u001b[39m | \u001b[39m6.626    \u001b[39m | \u001b[39m0.7719   \u001b[39m |\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m7.471    \u001b[39m | \u001b[39m0.1468   \u001b[39m | \u001b[39m8.851    \u001b[39m | \u001b[39m8.644    \u001b[39m | \u001b[39m296.6    \u001b[39m | \u001b[39m1.383    \u001b[39m | \u001b[39m9.727    \u001b[39m | \u001b[39m0.5807   \u001b[39m |\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.6255   \u001b[39m | \u001b[39m4.178    \u001b[39m | \u001b[39m0.1293   \u001b[39m | \u001b[39m9.002    \u001b[39m | \u001b[39m8.462    \u001b[39m | \u001b[39m263.7    \u001b[39m | \u001b[39m8.693    \u001b[39m | \u001b[39m0.2644   \u001b[39m | \u001b[39m0.9367   \u001b[39m |\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.7429   \u001b[39m | \u001b[39m9.068    \u001b[39m | \u001b[39m0.1533   \u001b[39m | \u001b[39m9.968    \u001b[39m | \u001b[39m0.3761   \u001b[39m | \u001b[39m288.5    \u001b[39m | \u001b[39m0.2456   \u001b[39m | \u001b[39m5.501    \u001b[39m | \u001b[39m0.9436   \u001b[39m |\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m-498.4   \u001b[39m | \u001b[39m0.604    \u001b[39m | \u001b[39m2.017    \u001b[39m | \u001b[39m0.09777  \u001b[39m | \u001b[39m5.526    \u001b[39m | \u001b[39m1.137    \u001b[39m | \u001b[39m261.8    \u001b[39m | \u001b[39m0.09592  \u001b[39m | \u001b[39m0.1074   \u001b[39m | \u001b[39m0.5252   \u001b[39m |\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-492.0   \u001b[39m | \u001b[39m0.5105   \u001b[39m | \u001b[39m9.758    \u001b[39m | \u001b[39m0.1773   \u001b[39m | \u001b[39m9.952    \u001b[39m | \u001b[39m8.554    \u001b[39m | \u001b[39m265.1    \u001b[39m | \u001b[39m7.046    \u001b[39m | \u001b[39m9.498    \u001b[39m | \u001b[39m0.5213   \u001b[39m |\n",
      "=====================================================================================================================================\n",
      "Best hyperparameters found: {'target': -490.0530069434556, 'params': {'colsample_bytree': 0.6021588795942798, 'gamma': 0.7576431997736432, 'learning_rate': 0.09173277975182814, 'max_depth': 9.77934658000206, 'min_child_weight': 8.732828864647947, 'n_estimators': 484.9545149137863, 'reg_alpha': 1.2057959281596986, 'reg_lambda': 9.936511835595034, 'subsample': 0.7742680571826623}}\n",
      "CPU times: total: 4h 2min 52s\n",
      "Wall time: 40min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "optimizer_xgb.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters found:\", optimizer_xgb.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "740b24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params_xgb = optimizer_xgb.max['params']\n",
    "best_params_xgb['n_estimators'] = int(best_params_xgb['n_estimators'])\n",
    "best_params_xgb['learning_rate'] = float(best_params_xgb['learning_rate'])\n",
    "best_params_xgb['max_depth'] = int(best_params_xgb['max_depth'])\n",
    "best_params_xgb['subsample'] = float(best_params_xgb['subsample'])\n",
    "best_params_xgb['colsample_bytree'] = float(best_params_xgb['colsample_bytree'])\n",
    "best_params_xgb['gamma'] = int(best_params_xgb['gamma'])\n",
    "best_params_xgb['min_child_weight'] = int(best_params_xgb['min_child_weight'])\n",
    "best_params_xgb['reg_alpha'] = int(best_params_xgb['reg_alpha'])\n",
    "best_params_xgb['reg_lambda'] = int(best_params_xgb['reg_lambda'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1b4f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31min 17s\n",
      "Wall time: 4min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6021588795942798, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09173277975182814, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=484, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6021588795942798, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09173277975182814, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=484, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6021588795942798, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.09173277975182814, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "             min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=484, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the final model with the best parameters\n",
    "xgb_best = xgb.XGBRegressor(**best_params_xgb, random_state=42)\n",
    "xgb_best.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c77dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.8 s\n",
      "Wall time: 5.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54aa2a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 13.471204736834606\n",
      "Mean Squared Error (MSE): 491.92009395433087\n",
      "Root Mean Squared Error (RMSE): 22.17927171830335\n",
      "R-squared (R2): 0.08927409230636985\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae_xgb}')\n",
    "print(f'Mean Squared Error (MSE): {mse_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_xgb}')\n",
    "print(f'R-squared (R2): {r2_xgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0d0cb",
   "metadata": {},
   "source": [
    "Initial Conclusions:  \n",
    "KNN model is too slow at predicting on a dataset this large. It also scored the worst on all evaluation metrics, so not a good model to use in our case.  \n",
    "  \n",
    "  \n",
    "Random Forest model performs better than the KNN model on its metrics, but is slow on training, so may not be the best model to use.  \n",
    "  \n",
    "  \n",
    "Both LightGBM and XGBoost perform better than Random Forest in all evaluation metrics. They also have a much faster training speed compared to the Random Forest, so these models would be better than either of the two previous models.  \n",
    "  \n",
    "  \n",
    "LightGBM is able to work with categorical features, without the need for one-hot encoding, so we will try a second LightGBM model, this time without splitting the catigorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554e859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e89609b",
   "metadata": {},
   "source": [
    "# LightGBM - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e2367e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.97 s\n",
      "Wall time: 7.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import train/test sets without one-hot encoding\n",
    "X_train_cat = pd.read_csv('X_train_cat.csv')\n",
    "X_test_cat = pd.read_csv('X_test_cat.csv')\n",
    "y_train_catdf = pd.read_csv('y_train_cat.csv')\n",
    "y_test_catdf = pd.read_csv('y_test_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bde46826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat target variable to be readable by machine models\n",
    "y_train_cat = y_train_catdf.values.ravel()\n",
    "y_test_cat = y_test_catdf.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e15b7677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5513433, 9)\n",
      "(5513433,)\n",
      "(1378359, 9)\n",
      "(1378359,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cat.shape)\n",
    "print(y_train_cat.shape)\n",
    "print(X_test_cat.shape)\n",
    "print(y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6554a042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5513433 entries, 0 to 5513432\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Date             object \n",
      " 1   Airline          object \n",
      " 2   Origin           object \n",
      " 3   Dest             object \n",
      " 4   Distance         float64\n",
      " 5   hour_depart      int64  \n",
      " 6   airflightnumber  object \n",
      " 7   day              object \n",
      " 8   month            int64  \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 378.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Preview data\n",
    "X_train_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bb26ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename day column to day_of_week column\n",
    "X_train_cat.rename(columns={'day': 'day_of_week'}, inplace=True)\n",
    "X_test_cat.rename(columns={'day': 'day_of_week'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f983e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change object type coumns to category columns to be compatible with the model\n",
    "X_train_cat[\"Airline\"] = X_train_cat[\"Airline\"].astype(\"category\")\n",
    "X_train_cat[\"Origin\"] = X_train_cat[\"Origin\"].astype(\"category\")\n",
    "X_train_cat[\"Dest\"] = X_train_cat[\"Dest\"].astype(\"category\")\n",
    "X_train_cat[\"day_of_week\"] = X_train_cat[\"day_of_week\"].astype(\"category\")\n",
    "X_train_cat['airflightnumber'] = X_train_cat['airflightnumber'].astype(\"category\")\n",
    "\n",
    "X_test_cat[\"Airline\"] = X_test_cat[\"Airline\"].astype(\"category\")\n",
    "X_test_cat[\"Origin\"] = X_test_cat[\"Origin\"].astype(\"category\")\n",
    "X_test_cat[\"Dest\"] = X_test_cat[\"Dest\"].astype(\"category\")\n",
    "X_test_cat[\"day_of_week\"] = X_test_cat[\"day_of_week\"].astype(\"category\")\n",
    "X_test_cat['airflightnumber'] = X_test_cat['airflightnumber'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01ff7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Date column into day (numerical day in the month) and week of the year column\n",
    "X_train_cat[\"Date\"] = pd.to_datetime(X_train_cat[\"Date\"])\n",
    "X_train_cat[\"day\"] = X_train_cat[\"Date\"].dt.day\n",
    "X_train_cat[\"week_of_year\"] = X_train_cat[\"Date\"].dt.isocalendar().week\n",
    "X_train_cat.drop(columns=[\"Date\"], inplace=True)\n",
    "\n",
    "X_test_cat[\"Date\"] = pd.to_datetime(X_test_cat[\"Date\"])\n",
    "X_test_cat[\"day\"] = X_test_cat[\"Date\"].dt.day\n",
    "X_test_cat[\"week_of_year\"] = X_test_cat[\"Date\"].dt.isocalendar().week\n",
    "X_test_cat.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "045e1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split month column into cyclical encoding (to deal with December to January rollover)\n",
    "X_train_cat[\"month_sin\"] = np.sin(2 * np.pi * X_test_cat[\"month\"] / 12)\n",
    "X_train_cat[\"month_cos\"] = np.cos(2 * np.pi * X_train_cat[\"month\"] / 12)\n",
    "\n",
    "X_test_cat[\"month_sin\"] = np.sin(2 * np.pi * X_test_cat[\"month\"] / 12)\n",
    "X_test_cat[\"month_cos\"] = np.cos(2 * np.pi * X_test_cat[\"month\"] / 12)\n",
    "\n",
    "X_train_cat.drop(columns=[\"month\"], inplace=True)\n",
    "X_test_cat.drop(columns=[\"month\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d5119d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HHMM to separate hour & minute columns\n",
    "X_train_cat[\"hour\"] = X_train_cat[\"hour_depart\"] // 100\n",
    "X_train_cat[\"minute\"] = X_train_cat[\"hour_depart\"] % 100\n",
    "\n",
    "X_test_cat[\"hour\"] = X_test_cat[\"hour_depart\"] // 100\n",
    "X_test_cat[\"minute\"] = X_test_cat[\"hour_depart\"] % 100\n",
    "\n",
    "\n",
    "# Convert to cyclical encoding (to deal with 2300 to 0000 rollover)\n",
    "X_train_cat[\"hour_sin\"] = np.sin(2 * np.pi * X_train_cat[\"hour\"] / 24)\n",
    "X_train_cat[\"hour_cos\"] = np.cos(2 * np.pi * X_train_cat[\"hour\"] / 24)\n",
    "X_train_cat[\"minute_sin\"] = np.sin(2 * np.pi * X_train_cat[\"minute\"] / 60)\n",
    "X_train_cat[\"minute_cos\"] = np.cos(2 * np.pi * X_train_cat[\"minute\"] / 60)\n",
    "\n",
    "X_test_cat[\"hour_sin\"] = np.sin(2 * np.pi * X_test_cat[\"hour\"] / 24)\n",
    "X_test_cat[\"hour_cos\"] = np.cos(2 * np.pi * X_test_cat[\"hour\"] / 24)\n",
    "X_test_cat[\"minute_sin\"] = np.sin(2 * np.pi * X_test_cat[\"minute\"] / 60)\n",
    "X_test_cat[\"minute_cos\"] = np.cos(2 * np.pi * X_test_cat[\"minute\"] / 60)\n",
    "\n",
    "\n",
    "# Drop original columns\n",
    "X_train_cat.drop(columns=[\"hour\", \"minute\"], inplace=True)\n",
    "X_train_cat.drop(columns=[\"hour_depart\"], inplace=True)\n",
    "\n",
    "X_test_cat.drop(columns=[\"hour\", \"minute\"], inplace=True)\n",
    "X_test_cat.drop(columns=[\"hour_depart\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "05d06a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Airflightnumber as it \n",
    "X_train_cat.drop(columns=[\"airflightnumber\"], inplace=True)\n",
    "X_test_cat.drop(columns=[\"airflightnumber\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0cc4647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fraction = 0.2\n",
    "\n",
    "X_traincat_sample, _, y_traincat_sample, _ = train_test_split(X_train_cat, y_train_cat, test_size=1-sample_fraction, random_state=42)\n",
    "X_testcat_sample, _, y_testcat_sample, _ = train_test_split(X_test_cat, y_test_cat, test_size=1-sample_fraction, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9004b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function to optimize\n",
    "def lgbcat_eval(n_estimators, learning_rate, num_leaves, max_depth, subsample, colsample_bytree, reg_alpha, reg_lambda):\n",
    "    \"\"\"\n",
    "    Trains a LightGBM with given hyperparameters and returns the returns -mse\n",
    "    \"\"\"\n",
    "    # Convert parameters appripirate types\n",
    "    n_estimators =  int(n_estimators)\n",
    "    learning_rate = float(learning_rate)\n",
    "    num_leaves = int(num_leaves)\n",
    "    max_depth = int(max_depth)\n",
    "    subsample = float(subsample)\n",
    "    colsample_bytree = float(colsample_bytree)\n",
    "    \n",
    "        \n",
    "    # Create Model\n",
    "    lgbbocat = lgb.LGBMRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    num_leaves=num_leaves,\n",
    "    max_depth=max_depth,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    reg_alpha = reg_alpha,\n",
    "    reg_lambda = reg_lambda,\n",
    "    random_state=42)\n",
    "    \n",
    "    # Train and test the model\n",
    "    lgbbocat.fit(X_train_cat, y_train_cat, categorical_feature=categorical_features)\n",
    "    y_pred_lgbbocat = lgbbocat.predict(X_test_cat)\n",
    "    mse = mean_squared_error(y_test_cat, y_pred_lgbbocat)\n",
    "    return -mse  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e776e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paramater bounds for testing\n",
    "param_bounds_lgbcat = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'learning_rate': (0.01, 0.2),    \n",
    "    'num_leaves': (20, 100),\n",
    "    'max_depth': (5, 50),  \n",
    "    'subsample': (0.6, 1.0),\n",
    "    \"colsample_bytree\": (0.6, 1.0)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "478f910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the optimizer\n",
    "optimizer_lgbcat = BayesianOptimization(\n",
    "    f=lgb_eval,\n",
    "    pbounds=param_bounds_lgb,\n",
    "    random_state=42,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad93a279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-493.2   \u001b[39m | \u001b[39m0.7498   \u001b[39m | \u001b[39m0.1906   \u001b[39m | \u001b[39m37.94    \u001b[39m | \u001b[39m339.5    \u001b[39m | \u001b[39m32.48    \u001b[39m | \u001b[39m0.6624   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-494.9   \u001b[39m | \u001b[39m0.6232   \u001b[39m | \u001b[39m0.1746   \u001b[39m | \u001b[39m32.05    \u001b[39m | \u001b[39m383.2    \u001b[39m | \u001b[39m21.65    \u001b[39m | \u001b[39m0.988    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-497.0   \u001b[39m | \u001b[39m0.933    \u001b[39m | \u001b[39m0.05034  \u001b[39m | \u001b[39m13.18    \u001b[39m | \u001b[39m173.4    \u001b[39m | \u001b[39m44.34    \u001b[39m | \u001b[39m0.8099   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-497.1   \u001b[39m | \u001b[39m0.7728   \u001b[39m | \u001b[39m0.06533  \u001b[39m | \u001b[39m32.53    \u001b[39m | \u001b[39m155.8    \u001b[39m | \u001b[39m43.37    \u001b[39m | \u001b[39m0.7465   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m-491.9   \u001b[39m | \u001b[35m0.7824   \u001b[39m | \u001b[35m0.1592   \u001b[39m | \u001b[35m13.99    \u001b[39m | \u001b[35m305.7    \u001b[39m | \u001b[35m67.39    \u001b[39m | \u001b[35m0.6186   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-495.3   \u001b[39m | \u001b[39m0.843    \u001b[39m | \u001b[39m0.0424   \u001b[39m | \u001b[39m7.927    \u001b[39m | \u001b[39m479.6    \u001b[39m | \u001b[39m97.25    \u001b[39m | \u001b[39m0.9234   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-499.9   \u001b[39m | \u001b[39m0.7218   \u001b[39m | \u001b[39m0.02856  \u001b[39m | \u001b[39m35.79    \u001b[39m | \u001b[39m276.1    \u001b[39m | \u001b[39m29.76    \u001b[39m | \u001b[39m0.7981   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-492.2   \u001b[39m | \u001b[39m0.6138   \u001b[39m | \u001b[39m0.1828   \u001b[39m | \u001b[39m16.65    \u001b[39m | \u001b[39m365.0    \u001b[39m | \u001b[39m44.94    \u001b[39m | \u001b[39m0.808    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-492.2   \u001b[39m | \u001b[39m0.8187   \u001b[39m | \u001b[39m0.04512  \u001b[39m | \u001b[39m48.63    \u001b[39m | \u001b[39m410.1    \u001b[39m | \u001b[39m95.16    \u001b[39m | \u001b[39m0.9579   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-496.4   \u001b[39m | \u001b[39m0.8392   \u001b[39m | \u001b[39m0.1852   \u001b[39m | \u001b[39m8.982    \u001b[39m | \u001b[39m178.4    \u001b[39m | \u001b[39m23.62    \u001b[39m | \u001b[39m0.7301   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m11       \u001b[39m | \u001b[35m-491.2   \u001b[39m | \u001b[35m0.8924   \u001b[39m | \u001b[35m0.09801  \u001b[39m | \u001b[35m19.58    \u001b[39m | \u001b[35m343.5    \u001b[39m | \u001b[35m90.1     \u001b[39m | \u001b[35m0.9535   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m-490.7   \u001b[39m | \u001b[35m0.8198   \u001b[39m | \u001b[35m0.1072   \u001b[39m | \u001b[35m49.23    \u001b[39m | \u001b[35m409.2    \u001b[39m | \u001b[35m95.07    \u001b[39m | \u001b[35m0.8312   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8587   \u001b[39m | \u001b[39m0.1573   \u001b[39m | \u001b[39m19.04    \u001b[39m | \u001b[39m344.3    \u001b[39m | \u001b[39m87.88    \u001b[39m | \u001b[39m0.8503   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6368   \u001b[39m | \u001b[39m0.08895  \u001b[39m | \u001b[39m48.24    \u001b[39m | \u001b[39m406.0    \u001b[39m | \u001b[39m93.83    \u001b[39m | \u001b[39m0.9499   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-493.8   \u001b[39m | \u001b[39m0.9778   \u001b[39m | \u001b[39m0.03388  \u001b[39m | \u001b[39m14.98    \u001b[39m | \u001b[39m340.5    \u001b[39m | \u001b[39m85.84    \u001b[39m | \u001b[39m0.7371   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6687   \u001b[39m | \u001b[39m0.1021   \u001b[39m | \u001b[39m20.57    \u001b[39m | \u001b[39m348.7    \u001b[39m | \u001b[39m91.4     \u001b[39m | \u001b[39m0.9575   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m17       \u001b[39m | \u001b[39m-490.9   \u001b[39m | \u001b[39m0.757    \u001b[39m | \u001b[39m0.1777   \u001b[39m | \u001b[39m15.89    \u001b[39m | \u001b[39m347.3    \u001b[39m | \u001b[39m91.9     \u001b[39m | \u001b[39m0.7009   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.6124   \u001b[39m | \u001b[39m0.1321   \u001b[39m | \u001b[39m16.02    \u001b[39m | \u001b[39m343.3    \u001b[39m | \u001b[39m96.6     \u001b[39m | \u001b[39m0.8716   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-495.9   \u001b[39m | \u001b[39m0.6375   \u001b[39m | \u001b[39m0.01938  \u001b[39m | \u001b[39m13.44    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m96.68    \u001b[39m | \u001b[39m0.9308   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.9795   \u001b[39m | \u001b[39m0.106    \u001b[39m | \u001b[39m22.67    \u001b[39m | \u001b[39m342.2    \u001b[39m | \u001b[39m95.82    \u001b[39m | \u001b[39m0.8041   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-490.9   \u001b[39m | \u001b[39m0.9091   \u001b[39m | \u001b[39m0.1259   \u001b[39m | \u001b[39m25.23    \u001b[39m | \u001b[39m347.9    \u001b[39m | \u001b[39m97.74    \u001b[39m | \u001b[39m0.8506   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.6756   \u001b[39m | \u001b[39m0.1502   \u001b[39m | \u001b[39m28.41    \u001b[39m | \u001b[39m349.0    \u001b[39m | \u001b[39m91.84    \u001b[39m | \u001b[39m0.9179   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.7267   \u001b[39m | \u001b[39m0.166    \u001b[39m | \u001b[39m27.32    \u001b[39m | \u001b[39m343.0    \u001b[39m | \u001b[39m91.97    \u001b[39m | \u001b[39m0.6264   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.6481   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m34.14    \u001b[39m | \u001b[39m344.2    \u001b[39m | \u001b[39m94.58    \u001b[39m | \u001b[39m0.8021   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.7883   \u001b[39m | \u001b[39m0.1399   \u001b[39m | \u001b[39m36.27    \u001b[39m | \u001b[39m347.6    \u001b[39m | \u001b[39m87.7     \u001b[39m | \u001b[39m0.6491   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-496.9   \u001b[39m | \u001b[39m0.6247   \u001b[39m | \u001b[39m0.01621  \u001b[39m | \u001b[39m34.69    \u001b[39m | \u001b[39m340.1    \u001b[39m | \u001b[39m88.65    \u001b[39m | \u001b[39m0.9066   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-494.8   \u001b[39m | \u001b[39m0.8831   \u001b[39m | \u001b[39m0.0176   \u001b[39m | \u001b[39m32.32    \u001b[39m | \u001b[39m349.0    \u001b[39m | \u001b[39m96.82    \u001b[39m | \u001b[39m0.6284   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-492.1   \u001b[39m | \u001b[39m0.7162   \u001b[39m | \u001b[39m0.04259  \u001b[39m | \u001b[39m49.67    \u001b[39m | \u001b[39m406.1    \u001b[39m | \u001b[39m99.99    \u001b[39m | \u001b[39m0.79     \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.9634   \u001b[39m | \u001b[39m0.1738   \u001b[39m | \u001b[39m20.53    \u001b[39m | \u001b[39m345.9    \u001b[39m | \u001b[39m95.98    \u001b[39m | \u001b[39m0.6947   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.6855   \u001b[39m | \u001b[39m0.132    \u001b[39m | \u001b[39m29.77    \u001b[39m | \u001b[39m347.4    \u001b[39m | \u001b[39m87.21    \u001b[39m | \u001b[39m0.6646   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m31       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.7006   \u001b[39m | \u001b[39m0.07743  \u001b[39m | \u001b[39m24.29    \u001b[39m | \u001b[39m345.0    \u001b[39m | \u001b[39m88.71    \u001b[39m | \u001b[39m0.916    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.9764   \u001b[39m | \u001b[39m0.162    \u001b[39m | \u001b[39m29.17    \u001b[39m | \u001b[39m341.2    \u001b[39m | \u001b[39m97.52    \u001b[39m | \u001b[39m0.8768   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m-491.4   \u001b[39m | \u001b[39m0.8895   \u001b[39m | \u001b[39m0.1034   \u001b[39m | \u001b[39m18.65    \u001b[39m | \u001b[39m350.7    \u001b[39m | \u001b[39m85.85    \u001b[39m | \u001b[39m0.9292   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.8095   \u001b[39m | \u001b[39m0.1033   \u001b[39m | \u001b[39m35.76    \u001b[39m | \u001b[39m353.1    \u001b[39m | \u001b[39m87.13    \u001b[39m | \u001b[39m0.6107   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.7182   \u001b[39m | \u001b[39m0.1435   \u001b[39m | \u001b[39m27.43    \u001b[39m | \u001b[39m353.8    \u001b[39m | \u001b[39m87.22    \u001b[39m | \u001b[39m0.9052   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8761   \u001b[39m | \u001b[39m0.1496   \u001b[39m | \u001b[39m31.52    \u001b[39m | \u001b[39m354.4    \u001b[39m | \u001b[39m79.57    \u001b[39m | \u001b[39m0.8664   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m-491.8   \u001b[39m | \u001b[39m0.7861   \u001b[39m | \u001b[39m0.09607  \u001b[39m | \u001b[39m26.63    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m79.63    \u001b[39m | \u001b[39m0.6329   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m-493.0   \u001b[39m | \u001b[39m0.9686   \u001b[39m | \u001b[39m0.04646  \u001b[39m | \u001b[39m38.89    \u001b[39m | \u001b[39m350.4    \u001b[39m | \u001b[39m82.27    \u001b[39m | \u001b[39m0.721    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.7842   \u001b[39m | \u001b[39m0.1406   \u001b[39m | \u001b[39m27.82    \u001b[39m | \u001b[39m358.7    \u001b[39m | \u001b[39m81.57    \u001b[39m | \u001b[39m0.8031   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m-491.1   \u001b[39m | \u001b[39m0.8854   \u001b[39m | \u001b[39m0.1557   \u001b[39m | \u001b[39m19.91    \u001b[39m | \u001b[39m357.5    \u001b[39m | \u001b[39m81.27    \u001b[39m | \u001b[39m0.6382   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m-491.9   \u001b[39m | \u001b[39m0.6863   \u001b[39m | \u001b[39m0.09805  \u001b[39m | \u001b[39m23.44    \u001b[39m | \u001b[39m358.5    \u001b[39m | \u001b[39m74.34    \u001b[39m | \u001b[39m0.6907   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m-492.8   \u001b[39m | \u001b[39m0.8604   \u001b[39m | \u001b[39m0.03836  \u001b[39m | \u001b[39m19.58    \u001b[39m | \u001b[39m337.1    \u001b[39m | \u001b[39m98.03    \u001b[39m | \u001b[39m0.7823   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m-494.2   \u001b[39m | \u001b[39m0.602    \u001b[39m | \u001b[39m0.02969  \u001b[39m | \u001b[39m33.7     \u001b[39m | \u001b[39m361.6    \u001b[39m | \u001b[39m85.53    \u001b[39m | \u001b[39m0.6644   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.9381   \u001b[39m | \u001b[39m0.1094   \u001b[39m | \u001b[39m39.66    \u001b[39m | \u001b[39m350.0    \u001b[39m | \u001b[39m91.72    \u001b[39m | \u001b[39m0.951    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m45       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.8137   \u001b[39m | \u001b[39m0.1144   \u001b[39m | \u001b[39m22.87    \u001b[39m | \u001b[39m357.6    \u001b[39m | \u001b[39m87.97    \u001b[39m | \u001b[39m0.9414   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m-493.4   \u001b[39m | \u001b[39m0.8412   \u001b[39m | \u001b[39m0.03587  \u001b[39m | \u001b[39m20.43    \u001b[39m | \u001b[39m363.6    \u001b[39m | \u001b[39m82.66    \u001b[39m | \u001b[39m0.7976   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.8035   \u001b[39m | \u001b[39m0.1824   \u001b[39m | \u001b[39m23.83    \u001b[39m | \u001b[39m354.0    \u001b[39m | \u001b[39m84.26    \u001b[39m | \u001b[39m0.8697   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m-491.3   \u001b[39m | \u001b[39m0.7469   \u001b[39m | \u001b[39m0.1286   \u001b[39m | \u001b[39m14.02    \u001b[39m | \u001b[39m355.6    \u001b[39m | \u001b[39m77.08    \u001b[39m | \u001b[39m0.6802   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m-491.9   \u001b[39m | \u001b[39m0.8837   \u001b[39m | \u001b[39m0.08547  \u001b[39m | \u001b[39m17.7     \u001b[39m | \u001b[39m352.9    \u001b[39m | \u001b[39m79.08    \u001b[39m | \u001b[39m0.7729   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m-492.3   \u001b[39m | \u001b[39m0.7981   \u001b[39m | \u001b[39m0.08442  \u001b[39m | \u001b[39m11.67    \u001b[39m | \u001b[39m359.0    \u001b[39m | \u001b[39m71.36    \u001b[39m | \u001b[39m0.758    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m-493.2   \u001b[39m | \u001b[39m0.9205   \u001b[39m | \u001b[39m0.04095  \u001b[39m | \u001b[39m14.38    \u001b[39m | \u001b[39m355.7    \u001b[39m | \u001b[39m84.88    \u001b[39m | \u001b[39m0.7245   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m-491.5   \u001b[39m | \u001b[39m0.8569   \u001b[39m | \u001b[39m0.1308   \u001b[39m | \u001b[39m30.25    \u001b[39m | \u001b[39m356.5    \u001b[39m | \u001b[39m73.2     \u001b[39m | \u001b[39m0.9018   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m-493.6   \u001b[39m | \u001b[39m0.7271   \u001b[39m | \u001b[39m0.03064  \u001b[39m | \u001b[39m26.27    \u001b[39m | \u001b[39m357.9    \u001b[39m | \u001b[39m93.55    \u001b[39m | \u001b[39m0.9044   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m-495.0   \u001b[39m | \u001b[39m0.9127   \u001b[39m | \u001b[39m0.03807  \u001b[39m | \u001b[39m9.088    \u001b[39m | \u001b[39m349.5    \u001b[39m | \u001b[39m73.58    \u001b[39m | \u001b[39m0.8963   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m-494.0   \u001b[39m | \u001b[39m0.7664   \u001b[39m | \u001b[39m0.03668  \u001b[39m | \u001b[39m30.26    \u001b[39m | \u001b[39m349.7    \u001b[39m | \u001b[39m70.25    \u001b[39m | \u001b[39m0.8892   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m-491.2   \u001b[39m | \u001b[39m0.9053   \u001b[39m | \u001b[39m0.1724   \u001b[39m | \u001b[39m31.54    \u001b[39m | \u001b[39m361.2    \u001b[39m | \u001b[39m76.53    \u001b[39m | \u001b[39m0.6179   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m-494.6   \u001b[39m | \u001b[39m0.826    \u001b[39m | \u001b[39m0.03258  \u001b[39m | \u001b[39m31.84    \u001b[39m | \u001b[39m361.0    \u001b[39m | \u001b[39m68.53    \u001b[39m | \u001b[39m0.9207   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m-491.0   \u001b[39m | \u001b[39m0.7266   \u001b[39m | \u001b[39m0.1852   \u001b[39m | \u001b[39m35.12    \u001b[39m | \u001b[39m340.1    \u001b[39m | \u001b[39m99.89    \u001b[39m | \u001b[39m0.636    \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m59       \u001b[39m | \u001b[39m-492.1   \u001b[39m | \u001b[39m0.9412   \u001b[39m | \u001b[39m0.05933  \u001b[39m | \u001b[39m42.57    \u001b[39m | \u001b[39m342.5    \u001b[39m | \u001b[39m94.67    \u001b[39m | \u001b[39m0.6863   \u001b[39m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 1102756, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 5.719183\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m-492.0   \u001b[39m | \u001b[39m0.7522   \u001b[39m | \u001b[39m0.05823  \u001b[39m | \u001b[39m49.23    \u001b[39m | \u001b[39m408.4    \u001b[39m | \u001b[39m89.1     \u001b[39m | \u001b[39m0.6895   \u001b[39m |\n",
      "=================================================================================================\n",
      "Best hyperparameters found: {'target': -490.6941216113791, 'params': {'colsample_bytree': 0.819758663105755, 'learning_rate': 0.1071949436149192, 'max_depth': 49.23290923768107, 'n_estimators': 409.1520297877578, 'num_leaves': 95.06636520965252, 'subsample': 0.8311833080516193}}\n",
      "CPU times: total: 59min 5s\n",
      "Wall time: 9min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run optimization\n",
    "optimizer_lgbcat.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters found:\", optimizer_lgbcat.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ded59b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params_lgbcat = optimizer_lgbcat.max['params']\n",
    "best_params_lgbcat['n_estimators'] = int(best_params_lgbcat['n_estimators'])\n",
    "best_params_lgbcat['learning_rate'] = float(best_params_lgbcat['learning_rate'])\n",
    "best_params_lgbcat['num_leaves'] = int(best_params_lgbcat['num_leaves'])\n",
    "best_params_lgbcat['max_depth'] = int(best_params_lgbcat['max_depth'])\n",
    "best_params_lgbcat['subsample'] = float(best_params_lgbcat['subsample'])\n",
    "best_params_lgbcat['colsample_bytree'] = float(best_params_lgbcat['colsample_bytree'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0d12754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 5513433, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 5.702085\n",
      "CPU times: total: 7min 27s\n",
      "Wall time: 59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.819758663105755,\n",
       "              learning_rate=0.1071949436149192, max_depth=49, n_estimators=409,\n",
       "              num_leaves=95, random_state=42, subsample=0.8311833080516193)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the final model with the best parameters\n",
    "lgbc_best = lgb.LGBMRegressor(**best_params_lgbcat, random_state=42)\n",
    "lgbc_best.fit(X_train_cat, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc0d98dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.3 s\n",
      "Wall time: 7.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions\n",
    "y_pred_lgbc = lgbc_best.predict(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d689c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 12.810996187940953\n",
      "Mean Squared Error (MSE): 455.97570928808085\n",
      "Root Mean Squared Error (RMSE): 21.35358773808469\n",
      "R-squared (R2): 0.16012999489620683\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae_lgbc = mean_absolute_error(y_test_cat, y_pred_lgbc)\n",
    "mse_lgbc = mean_squared_error(y_test_cat, y_pred_lgbc)\n",
    "rmse_lgbc = np.sqrt(mse_lgbc)\n",
    "r2_lgbc = r2_score(y_test_cat, y_pred_lgbc)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {mae_lgbc}')\n",
    "print(f'Mean Squared Error (MSE): {mse_lgbc}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lgbc}')\n",
    "print(f'R-squared (R2): {r2_lgbc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f61ec",
   "metadata": {},
   "source": [
    "Conclusion:  \n",
    "This model performs better than XGBoost and the 1st LightGBM model in all metrics/ Based on this, the 2nd LightGBM model is the best model to use of the model's tested. That being said, there is much room for improvement. Currently, this model only explains approximately 16% of the variance in the data.\n",
    "\n",
    "Possible improvements could be made by having more features, such as data across multiple years, the reason for each delay, weather information during each flight, or if the previous flight was delayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7958f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
